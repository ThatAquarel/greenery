{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO = \"GEODGHR4\"\n",
    "GEN_015 = \"GEN_015\"\n",
    "SDC_015 = \"SDC_015\"\n",
    "NDVI = \"NDVI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\xia_t\\\\Desktop\\\\Projects\\\\youreka\\\\dataset\\\\all_subsetted_group.csv\")\n",
    "\n",
    "# filter mental health and indigenous status\n",
    "data = data.loc[data[SDC_015] <= 2]\n",
    "data = data.loc[data[GEN_015] <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize NDVI into a range of [0, 1]\n",
    "n = data[NDVI]\n",
    "data[NDVI] = (n - n.min()) / (n.max() - n.min())\n",
    "\n",
    "# min 0.40255\n",
    "# 0.53163_\n",
    "# 0.660716_\n",
    "# max 0.7898"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique respondant identifier\n",
    "import uuid\n",
    "\n",
    "sample_n = len(data)\n",
    "uuids = [str(uuid.uuid4()) for _ in range(sample_n)]\n",
    "data[\"UUID\"] = uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize NDVI into N_BINS intervals\n",
    "N_BINS = 3\n",
    "bins = np.linspace(0, 1, N_BINS + 1)\n",
    "\n",
    "for i in range(N_BINS):\n",
    "    lower = bins[i]\n",
    "    upper = bins[i + 1]\n",
    "\n",
    "    inclusive = \"right\"\n",
    "    if i == 0:\n",
    "        inclusive = \"both\"\n",
    "\n",
    "    data.loc[data[\"NDVI\"].between(lower, upper, inclusive), \"NDVI_BINS\"] = i\n",
    "\n",
    "data[\"NDVI\"] = data[\"NDVI_BINS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.contingency import crosstab\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats.contingency import association\n",
    "\n",
    "class TestResult:\n",
    "    def __init__(self, chi2, cramer) -> None:\n",
    "        self.chi2 = chi2\n",
    "        self.cramer = cramer\n",
    "\n",
    "\n",
    "def chi2_test(contingency_table, a = True):\n",
    "    return TestResult(\n",
    "        chi2_contingency(contingency_table, correction=True),\n",
    "        association(contingency_table, method=\"cramer\", correction=True) if a else None,\n",
    "    )\n",
    "\n",
    "def gen_table(cols, data):\n",
    "    return crosstab(*[data[col] for col in cols]).count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d022bb886704a0d88bc125891b1b302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import trange\n",
    "\n",
    "grouped_sdc_015 = data.groupby([SDC_015])\n",
    "grouped_ndvi = data.groupby([NDVI])\n",
    "grouped_inter = data.groupby([SDC_015, NDVI])\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for i in trange(250):\n",
    "    data_sdc_015 = grouped_sdc_015.apply(lambda x: x.sample(67, random_state=i).reset_index(drop=True))\n",
    "    contingency_sdc_015 = gen_table([SDC_015, GEN_015], data_sdc_015)\n",
    "    sdc_015 = chi2_test(contingency_sdc_015)\n",
    "\n",
    "    data_ndvi = grouped_ndvi.apply(lambda x: x.sample(65, random_state=i).reset_index(drop=True))\n",
    "    contingency_ndvi = gen_table([NDVI, GEN_015], data_ndvi)\n",
    "    ndvi = chi2_test(contingency_ndvi)\n",
    "\n",
    "    data_inter = grouped_inter.apply(lambda x: x.sample(47, random_state=i).reset_index(drop=True))\n",
    "    contingency_inter = gen_table([SDC_015, NDVI, GEN_015], data_inter)\n",
    "    inter = chi2_test(contingency_inter, a=False)\n",
    "\n",
    "    results_list.append((sdc_015, ndvi, inter, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTS = [\n",
    "    SDC_015,\n",
    "    NDVI,\n",
    "    \"INTER\"\n",
    "]\n",
    "\n",
    "PROPERTIES = {\n",
    "    \"STATISTIC\": lambda x: x.chi2.statistic,\n",
    "    \"PVALUE\": lambda x: x.chi2.pvalue,\n",
    "    \"DOF\": lambda x: x.chi2.dof,\n",
    "    \"CRAMERV\": lambda x: x.cramer\n",
    "}\n",
    "\n",
    "cols = [\n",
    "    f\"{test}_{property_}\"\n",
    "    for test in TESTS\n",
    "    for property_ in PROPERTIES\n",
    "]\n",
    "cols.append(\"SEED\")\n",
    "results = pd.DataFrame(index=np.arange(len(results_list)), columns=cols)\n",
    "\n",
    "for i, res in enumerate(results_list):\n",
    "    row = []\n",
    "    for test in res[:-1]:\n",
    "        for unpack_function in PROPERTIES.values():\n",
    "            row.append(unpack_function(test))\n",
    "    \n",
    "    row.append(res[-1])\n",
    "    results.loc[i] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"tests.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
